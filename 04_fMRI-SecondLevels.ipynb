{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DARPA-ARC Notebook 4: fMRI Second Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute Permutations\n",
    "Based on intial calculations, we assume one full loop of WLS + TFCE will take ~17s. We will submit jobs of 100 iterations (approx. 30 minutes time on cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T15:47:48.882501Z",
     "start_time": "2019-04-19T15:47:37.500450Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import os, op, np, root_dir, version, n_subj, n_permutations, inc\n",
    "\n",
    "np.random.seed(47404)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Generate permutations.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "permutations = []\n",
    "while True:\n",
    "    arr = np.random.choice([1,-1],n_subj,replace=True)\n",
    "    if not np.any(np.apply_along_axis(np.array_equal, 0, permutations, arr)): \n",
    "        permutations.append(arr)\n",
    "    if len(permutations) >= n_permutations: \n",
    "        break \n",
    "        \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Save.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "permutations = np.array(permutations)\n",
    "index = np.arange(0,n_permutations+1,inc)\n",
    "for n, ix in enumerate(index[1:]):\n",
    "    np.save(op.join(root_dir, 'fmri_second_levels', 'permutations', '%s_sign_flips_%s' % (version, (n+1))), permutations[ix-inc:ix])\n",
    "    \n",
    "with open(op.join(op.join(root_dir, 'fmri_second_levels', '%s_permutations.txt' % version)), 'w') as f:\n",
    "     f.write('\\n'.join(['%i' % i for i in np.arange(n_permutations/inc+1)]))\n",
    "            \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Surface Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T18:21:18.856990Z",
     "start_time": "2019-04-19T18:21:04.214560Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, subj_dir, \n",
    "                         label_dir, rois, task)\n",
    "from mne import read_label, read_surface, spatial_tris_connectivity, set_log_level\n",
    "set_log_level(verbose=False) \n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Make labels.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "\n",
    "for hemi in ['lh', 'rh']:\n",
    "    #\n",
    "    ## Assemble and merge labels.\n",
    "    label = []\n",
    "    for roi in rois: label.append(read_label(op.join(label_dir,'%s-%s.label' % (roi, hemi))))\n",
    "    label = np.sum(label)\n",
    "    #\n",
    "    ## Save label.\n",
    "    label.name = '%s-%s' % (task, hemi)\n",
    "    label.save(op.join(root_dir, 'fmri_second_levels/%s-%s.label' % (task, hemi)))\n",
    "    #\n",
    "    ## Load surface.\n",
    "    _, tris = read_surface(op.join(subj_dir, 'surf', '%s.white' % hemi))\n",
    "    mapping = np.in1d(np.unique(tris),label.vertices)\n",
    "    #\n",
    "    ## Reduce triangles to those in label.\n",
    "    ix = np.all(np.apply_along_axis(np.in1d, 0, tris, label.vertices), axis=1)\n",
    "    tris = tris[ix]\n",
    "    #\n",
    "    ## Compute connectivity.\n",
    "    coo = spatial_tris_connectivity(tris, remap_vertices=True)\n",
    "    np.savez(op.join(root_dir, 'fmri_second_levels/%s_%s_connectivity' % (version, hemi)), data = coo.data, row = coo.row,\n",
    "             col = coo.col, shape = coo.shape, mapping=mapping, vertices=label.vertices)\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Volume Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T18:21:22.655424Z",
     "start_time": "2019-04-19T18:21:21.726021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, subj_dir, \n",
    "                         roi_dict, asegf)\n",
    "                        \n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "lut = '/usr/local/freesurfer/stable5_3_0/FreeSurferColorLUT.txt'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Create mask.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load aseg.\n",
    "aseg = nib.load(asegf).get_data()\n",
    "\n",
    "## Find all voxels in ROI list. Get corresponding labels.\n",
    "mapping = np.in1d(aseg, list(roi_dict.keys())).reshape(aseg.shape)\n",
    "voxels = np.where(mapping)\n",
    "names = np.array([roi_dict[i] for i in aseg[voxels]])\n",
    "voxels = np.vstack(voxels).T\n",
    "\n",
    "## Initialize connectivity matrix.\n",
    "n_voxels, _ = voxels.shape\n",
    "coo = np.zeros([n_voxels,n_voxels], dtype=int)\n",
    "\n",
    "## Iteratively test for adjacency.\n",
    "## Here we use 6-lattice connectivity (up,down,forward,backward,left,right).\n",
    "for n in range(n_voxels):\n",
    "    diff = np.linalg.norm(voxels - voxels[n], axis=1)\n",
    "    M, = np.where(diff==1.)\n",
    "    for m in M: coo[n,m] = 1 \n",
    "coo = coo_matrix(coo)\n",
    "    \n",
    "## Save.\n",
    "np.savez(op.join(root_dir, 'fmri_second_levels/%s_mni305_connectivity' % version), data = coo.data, row = coo.row,\n",
    "         col = coo.col, shape = coo.shape, mapping=mapping, voxels=voxels, names=names)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Mean Signal from ROIs\n",
    "Necessary for computing percent signal change down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T19:22:09.999346Z",
     "start_time": "2019-04-19T18:21:27.261783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lh\n",
      "rh\n",
      "mni305\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir, task,\n",
    "                         session)\n",
    "\n",
    "## Define TR onsets.\n",
    "tr_onsets = np.insert( np.cumsum( np.ones(n_acq - 1) * tr ), 0, 0 )\n",
    "\n",
    "mean_signal = dict()\n",
    "for space in ['lh','rh','mni305']:\n",
    "    #\n",
    "    print(space)\n",
    "    #\n",
    "    ## Load masks.\n",
    "    npz = np.load(op.join(root_dir,'fmri_second_levels/%s_%s_connectivity.npz' % (version, space)))\n",
    "    include = npz['mapping']\n",
    "    #\n",
    "    ## Preallocate space.\n",
    "    ms = np.zeros([len(subjects), include.sum()])\n",
    "    #\n",
    "    ## Iterate over subjects.\n",
    "    for n, subject in enumerate(subjects):\n",
    "        #\n",
    "        ## Load data.\n",
    "        subj_dir = op.join(root_dir, 'fmri_first_levels', subject, '%s_%03d' % (task, session), '%03d' % session)\n",
    "        if space == 'mni305': f = op.join(subj_dir,'fmcpr.sm%s.%s.2mm.b0dc.nii.gz' % (sm, space))\n",
    "        else: f = op.join(subj_dir,'fmcpr.sm%s.fsaverage.%s.b0dc.nii.gz' % (sm, space))\n",
    "        data = nib.load(f).get_data()\n",
    "        #\n",
    "        ## Censor data. Average across acquisitions.\n",
    "        try: censor = np.loadtxt(op.join(subj_dir, '%s.censor.%s.par' % (version, fd)))\n",
    "        except IOError: censor = []\n",
    "        censor = np.invert(np.in1d(tr_onsets, censor))\n",
    "        #\n",
    "        data = data[include,...].squeeze()\n",
    "        data = data[...,censor].mean(axis=1)\n",
    "        #\n",
    "        ## Append.\n",
    "        ms[n] = data\n",
    "    #\n",
    "    ## Store in dictionary.\n",
    "    mean_signal[space] = ms\n",
    "    \n",
    "## Save.\n",
    "f = op.join(root_dir, 'fmri_second_levels/%s_mean_signal' % version)\n",
    "np.savez_compressed(f, lh = mean_signal['lh'], rh = mean_signal['rh'], mni305 = mean_signal['mni305'])\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T21:13:28.903792Z",
     "start_time": "2019-04-24T21:13:12.784090Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchical PCA VariableEpochs lh Control\n",
      "hierarchical PCA VariableEpochs lh DDB\n",
      "hierarchical PCA VariableEpochs lh Risk\n",
      "hierarchical PCA VariableEpochs lh Reward\n",
      "hierarchical PCA VariableEpochs rh Control\n",
      "hierarchical PCA VariableEpochs rh DDB\n",
      "hierarchical PCA VariableEpochs rh Risk\n",
      "hierarchical PCA VariableEpochs rh Reward\n",
      "hierarchical PCA VariableEpochs mni305 Control\n",
      "hierarchical PCA VariableEpochs mni305 DDB\n",
      "hierarchical PCA VariableEpochs mni305 Risk\n",
      "hierarchical PCA VariableEpochs mni305 Reward\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir,\n",
    "                         concat_sess_dir, thresholds, spaces, models,\n",
    "                         task, models, conditions_dict)\n",
    "from mne import read_label\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "for model_name, analysis, epochs_type in models:\n",
    "    #\n",
    "    for space in spaces:\n",
    "        #\n",
    "        ## Load masks.\n",
    "        npz = np.load(op.join(root_dir, 'fmri_second_levels/%s_%s_connectivity.npz' % (version, space)))\n",
    "        include = npz['mapping']\n",
    "        #\n",
    "        results_dir = op.join(concat_sess_dir, ('%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                (version, task, model_name, \n",
    "                                                 analysis, epochs_type, \n",
    "                                                 sm, fd, space)))\n",
    "        #\n",
    "        for condition in ['Control'] + conditions_dict[analysis]:\n",
    "            #\n",
    "            print(model_name, analysis, epochs_type, space, condition)\n",
    "            #\n",
    "            condition_dir = op.join(results_dir, ('%s.%s.%s.%s.%s.par' %\n",
    "                                                  (version, model_name,\n",
    "                                                   analysis, epochs_type,\n",
    "                                                   condition)))\n",
    "            #\n",
    "            ## Make save directory.\n",
    "            out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                               (version, task, model_name, \n",
    "                                                                analysis, epochs_type,\n",
    "                                                                sm, fd, space, condition)))\n",
    "            if not op.isdir(out_dir): os.makedirs(out_dir)\n",
    "            #\n",
    "            ## Load data.\n",
    "            ces = nib.load(op.join(condition_dir, 'ces.nii.gz')).get_data().squeeze()\n",
    "            cesvar = nib.load(op.join(condition_dir, 'cesvar.nii.gz')).get_data().squeeze()\n",
    "            affine = nib.load(op.join(condition_dir, 'ces.nii.gz')).affine\n",
    "            #\n",
    "            ## Masking.\n",
    "            ces = ces[include,...]\n",
    "            cesvar = cesvar[include,...]\n",
    "            #       \n",
    "            ## Save.\n",
    "            np.savez_compressed(op.join(out_dir, 'first_levels'), \n",
    "                                ces=ces.squeeze(), cesvar=cesvar.squeeze())\n",
    "            np.save(op.join(out_dir, 'affine'), affine)\n",
    "        \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform WLS Permutations\n",
    "\n",
    "This is done on on a cluster or in parallel using the fmri_second_levels/wls_perm.csh and fmri_second_levels/wls_perm.py scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T16:28:53.468216Z",
     "start_time": "2019-04-29T16:28:50.429406Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchical DelibMod VariableEpochs mni305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-097fd448a51d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m## Perform WLS.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mBmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/karima_001/users/DARPA-ARC/my_settings.py\u001b[0m in \u001b[0;36mwls\u001b[0;34m(X, Y, W)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mssr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_subj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mcov_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/karima_001/users/alex/software/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir,\n",
    "                         concat_sess_dir, thresholds, task, n_subj,\n",
    "                         X, n_subj, n_pred, prepare_image,\n",
    "                         load_sparse_coo, wls, spaces, models,\n",
    "                         conditions_dict)\n",
    "from mne.stats.cluster_level import _find_clusters as find_clusters\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "space = spaces[-1]\n",
    "model_name, analysis, epochs_type = models[0]\n",
    "#\n",
    "print(model_name, analysis, epochs_type, space)\n",
    "#\n",
    "## Permutation parameters.\n",
    "permutations = 0\n",
    "\n",
    "'''\n",
    "from subprocess import call # DEBUGGING\n",
    "regressor = '.'.join([version, model_name, analysis, epochs_type, conditions_dict[analysis][-1], 'par'])\n",
    "args = [space, regressor, permutations]\n",
    "call(['python fmri_second_levels/wls_perm.py %s %s %s' % (space, regressor, permutations)], env=os.environ, shell=True)\n",
    "'''\n",
    "\n",
    "## TFCE parameters.\n",
    "threshold = dict(start=0.1, step=0.1, h_power=2, e_power=0.5)\n",
    "tail = 0\n",
    "max_step = 1\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and prepare data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                   (version, task, model_name, \n",
    "                                                    analysis, epochs_type,\n",
    "                                                    sm, fd, space, condition)))\n",
    "## Load data.\n",
    "npz = np.load(os.path.join(out_dir, 'first_levels.npz'))\n",
    "ces = npz['ces']\n",
    "cesvar = np.abs( 1. / npz['cesvar'] )\n",
    "\n",
    "## Define indices.\n",
    "connectivity = load_sparse_coo(os.path.join(root_dir, 'fmri_second_levels',\n",
    "                               '%s_%s_connectivity.npz' % (version, space)))\n",
    "index,  = np.where(~np.isinf(cesvar).sum(axis=1).astype(bool))\n",
    "include = ~np.isinf(cesvar).sum(axis=1).astype(bool)\n",
    "    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Setup for permutation testing.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## If specified, load precomputed sign flips.\n",
    "if permutations: \n",
    "    sign_flips = np.load(os.path.join(root_dir, 'fmri_second_levels', \n",
    "                                      'permutations',\n",
    "                                      '%s_sign_flips_%s.npy' % (version, permutations)))\n",
    "else: \n",
    "    sign_flips = np.ones((1,n_subj))\n",
    "n_shuffles = sign_flips.shape[0]\n",
    "\n",
    "## Preallocate arrays for results.\n",
    "shape = [n_shuffles] + list(ces.shape[:-1])\n",
    "Bmap = np.zeros(shape)\n",
    "Fmap = np.zeros(shape)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Loop it!\n",
    "for n, sf in enumerate(sign_flips):\n",
    "    #\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Compute statistics.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    #\n",
    "    for m in index:\n",
    "        #\n",
    "        ## Update variables.\n",
    "        W = np.diag(cesvar[m])\n",
    "        Y = ces[m]\n",
    "        #\n",
    "        ## Permute values.\n",
    "        ## See Winkler et al. (2014), pg. 385\n",
    "        ## To compute Hat Matrix, see: https://en.wikipedia.org/wiki/Projection_matrix and \n",
    "        Z = X[:,1:]\n",
    "        ZZ = Z.dot( np.linalg.inv( Z.T.dot(W).dot(Z) ) ).dot(Z.T).dot(W)\n",
    "        Rz = np.identity(n_subj) - ZZ\n",
    "        Y = np.diag(sf).dot(Rz).dot(Y)\n",
    "        #\n",
    "        ## Perform WLS.\n",
    "        Bmap[n,m], Fmap[n,m] = wls(X,Y,W) \n",
    "    #\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Perform TFCE.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    #\n",
    "    _, Fmap[n] = find_clusters(Fmap[n], threshold, tail=tail, connectivity=connectivity, \n",
    "                               include=include, max_step=max_step, show_info=False)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Save results.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#  \n",
    "        \n",
    "if permutations: \n",
    "    f = op.join(out_dir, ('%s.%s.%s.%s.%s.%s.%s.%s.%s_perm-%s' % \n",
    "                          (version, task, model_name, analysis,\n",
    "                           epochs_type, sm, fd, space,\n",
    "                           condition, permutations)))\n",
    "else:\n",
    "    f = op.join(out_dir, ('%s.%s.%s.%s.%s.%s.%s.%s.%s_obs' % \n",
    "                          (version, task, model_name, analysis,\n",
    "                           epochs_type, sm, fd, space, condition)))\n",
    "np.savez_compressed(f, Bmap=Bmap, Fmap=Fmap)\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform FWE Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T14:26:52.051090Z",
     "start_time": "2019-04-30T14:10:44.557166Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchical PCA VariableEpochs Control lh\n",
      "hierarchical PCA VariableEpochs Control rh\n",
      "hierarchical PCA VariableEpochs Control mni305\n",
      "hierarchical PCA VariableEpochs DDB lh\n",
      "hierarchical PCA VariableEpochs DDB rh\n",
      "hierarchical PCA VariableEpochs DDB mni305\n",
      "hierarchical PCA VariableEpochs Risk lh\n",
      "hierarchical PCA VariableEpochs Risk rh\n",
      "hierarchical PCA VariableEpochs Risk mni305\n",
      "hierarchical PCA VariableEpochs Reward lh\n",
      "hierarchical PCA VariableEpochs Reward rh\n",
      "hierarchical PCA VariableEpochs Reward mni305\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir,\n",
    "                         concat_sess_dir, thresholds,\n",
    "                         spaces, task, prepare_image, models,\n",
    "                         conditions_dict, n_permutations, inc)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "permutations = np.arange(int(n_permutations/inc)) + 1\n",
    "\n",
    "for model_name, analysis, epochs_type in models:\n",
    "    #\n",
    "    for condition in ['Control'] + conditions_dict[analysis]:\n",
    "        #\n",
    "        for space in spaces:\n",
    "            #\n",
    "            print(model_name, analysis, epochs_type, condition, space)\n",
    "            #\n",
    "            out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                               (version, task, model_name, \n",
    "                                                                analysis, epochs_type,\n",
    "                                                                sm, fd, space, condition)))\n",
    "            obs_f = op.join(out_dir, ('%s.%s.%s.%s.%s.%s.%s.%s.%s_obs.npz' % \n",
    "                                      (version, task, model_name, analysis,\n",
    "                                       epochs_type, sm, fd, space, condition)))\n",
    "            #\n",
    "            ## Load true effects.\n",
    "            npz = np.load(obs_f)\n",
    "            Bmap = npz['Bmap'].squeeze()\n",
    "            Fmap = npz['Fmap'].squeeze()\n",
    "            #\n",
    "            ## Load permutations.\n",
    "            perm_f = op.join(out_dir, ('%s.%s.%s.%s.%s.%s.%s.%s.%s' %\n",
    "                                       (version, task, model_name, analysis,\n",
    "                                        epochs_type, sm, fd, space, condition)) + \n",
    "                                       '_perm-%s.npz')\n",
    "            Pmap = []\n",
    "            for p in permutations:\n",
    "                try:\n",
    "                    npz = np.load(perm_f % p)\n",
    "                    Pmap.append(npz['Fmap'])\n",
    "                except Exception as e:\n",
    "                    print(e, p)  # I was getting bad magic numbers on some file and had to rerun WLS\n",
    "            Pmap = np.concatenate(Pmap, axis=0)\n",
    "            n_permutations, _ = Pmap.shape\n",
    "            #\n",
    "            ## Compute p-values via FWE.\n",
    "            p_values = np.ones_like(Fmap)\n",
    "            for mp in Pmap.max(axis=1): p_values += mp > Fmap\n",
    "            p_values /= n_permutations + 1.\n",
    "            p_values = -np.log10(p_values) * np.sign(Bmap)\n",
    "            #\n",
    "            ## Save maps.\n",
    "            out_f = op.join(out_dir, ('%s.%s.%s.%s.%s.%s.%s.%s.%s_fwe' % \n",
    "                                      (version, task, model_name, analysis,\n",
    "                                       epochs_type, sm, fd, space, condition)))\n",
    "            np.save(out_f, p_values)\n",
    "            for arr, name in zip([Bmap,Fmap,p_values],['beta', 'F', 'fwe']):\n",
    "                image = prepare_image(arr, space)\n",
    "                image = nib.Nifti1Image(image, np.load(op.join(out_dir, 'affine.npy')))\n",
    "                nib.save(image, op.join(out_dir, '%s.nii.gz' % name))\n",
    "            \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform FDR Corrections\n",
    "Not used, but programmed for example's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T14:59:22.923036Z",
     "start_time": "2019-04-30T14:35:21.861175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchical DelibMod VariableEpochs Control lh\n",
      "hierarchical DelibMod VariableEpochs Control rh\n",
      "hierarchical DelibMod VariableEpochs Control mni305\n",
      "hierarchical DelibMod VariableEpochs DDB lh\n",
      "hierarchical DelibMod VariableEpochs DDB rh\n",
      "hierarchical DelibMod VariableEpochs DDB mni305\n",
      "non-hierarchical DelibMod VariableEpochs Control lh\n",
      "non-hierarchical DelibMod VariableEpochs Control rh\n",
      "non-hierarchical DelibMod VariableEpochs Control mni305\n",
      "non-hierarchical DelibMod VariableEpochs DDB lh\n",
      "non-hierarchical DelibMod VariableEpochs DDB rh\n",
      "non-hierarchical DelibMod VariableEpochs DDB mni305\n",
      "hierarchical DelibMod FixedEpochs Control lh\n",
      "hierarchical DelibMod FixedEpochs Control rh\n",
      "hierarchical DelibMod FixedEpochs Control mni305\n",
      "hierarchical DelibMod FixedEpochs DDB lh\n",
      "hierarchical DelibMod FixedEpochs DDB rh\n",
      "hierarchical DelibMod FixedEpochs DDB mni305\n",
      "non-hierarchical DelibMod FixedEpochs Control lh\n",
      "non-hierarchical DelibMod FixedEpochs Control rh\n",
      "non-hierarchical DelibMod FixedEpochs Control mni305\n",
      "non-hierarchical DelibMod FixedEpochs DDB lh\n",
      "non-hierarchical DelibMod FixedEpochs DDB rh\n",
      "non-hierarchical DelibMod FixedEpochs DDB mni305\n",
      "parameter Risk VariableEpochs Control lh\n",
      "parameter Risk VariableEpochs Control rh\n",
      "parameter Risk VariableEpochs Control mni305\n",
      "parameter Risk VariableEpochs Risk lh\n",
      "parameter Risk VariableEpochs Risk rh\n",
      "parameter Risk VariableEpochs Risk mni305\n",
      "parameter Reward VariableEpochs Control lh\n",
      "parameter Reward VariableEpochs Control rh\n",
      "parameter Reward VariableEpochs Control mni305\n",
      "parameter Reward VariableEpochs Reward lh\n",
      "parameter Reward VariableEpochs Reward rh\n",
      "parameter Reward VariableEpochs Reward mni305\n",
      "parameter Risk FixedEpochs Control lh\n",
      "parameter Risk FixedEpochs Control rh\n",
      "parameter Risk FixedEpochs Control mni305\n",
      "parameter Risk FixedEpochs Risk lh\n",
      "parameter Risk FixedEpochs Risk rh\n",
      "parameter Risk FixedEpochs Risk mni305\n",
      "parameter Reward FixedEpochs Control lh\n",
      "parameter Reward FixedEpochs Control rh\n",
      "parameter Reward FixedEpochs Control mni305\n",
      "parameter Reward FixedEpochs Reward lh\n",
      "parameter Reward FixedEpochs Reward rh\n",
      "parameter Reward FixedEpochs Reward mni305\n",
      "hierarchical All VariableEpochs Control lh\n",
      "hierarchical All VariableEpochs Control rh\n",
      "hierarchical All VariableEpochs Control mni305\n",
      "hierarchical All VariableEpochs DDB lh\n",
      "hierarchical All VariableEpochs DDB rh\n",
      "hierarchical All VariableEpochs DDB mni305\n",
      "hierarchical All VariableEpochs Risk lh\n",
      "hierarchical All VariableEpochs Risk rh\n",
      "hierarchical All VariableEpochs Risk mni305\n",
      "hierarchical All VariableEpochs Reward lh\n",
      "hierarchical All VariableEpochs Reward rh\n",
      "hierarchical All VariableEpochs Reward mni305\n",
      "hierarchical All FixedEpochs Control lh\n",
      "hierarchical All FixedEpochs Control rh\n",
      "hierarchical All FixedEpochs Control mni305\n",
      "hierarchical All FixedEpochs DDB lh\n",
      "hierarchical All FixedEpochs DDB rh\n",
      "hierarchical All FixedEpochs DDB mni305\n",
      "hierarchical All FixedEpochs Risk lh\n",
      "hierarchical All FixedEpochs Risk rh\n",
      "hierarchical All FixedEpochs Risk mni305\n",
      "hierarchical All FixedEpochs Reward lh\n",
      "hierarchical All FixedEpochs Reward rh\n",
      "hierarchical All FixedEpochs Reward mni305\n",
      "non-hierarchical All VariableEpochs Control lh\n",
      "non-hierarchical All VariableEpochs Control rh\n",
      "non-hierarchical All VariableEpochs Control mni305\n",
      "non-hierarchical All VariableEpochs DDB lh\n",
      "non-hierarchical All VariableEpochs DDB rh\n",
      "non-hierarchical All VariableEpochs DDB mni305\n",
      "non-hierarchical All VariableEpochs Risk lh\n",
      "non-hierarchical All VariableEpochs Risk rh\n",
      "non-hierarchical All VariableEpochs Risk mni305\n",
      "non-hierarchical All VariableEpochs Reward lh\n",
      "non-hierarchical All VariableEpochs Reward rh\n",
      "non-hierarchical All VariableEpochs Reward mni305\n",
      "non-hierarchical All FixedEpochs Control lh\n",
      "non-hierarchical All FixedEpochs Control rh\n",
      "Bad magic number for file header 4\n",
      "non-hierarchical All FixedEpochs Control mni305\n",
      "non-hierarchical All FixedEpochs DDB lh\n",
      "non-hierarchical All FixedEpochs DDB rh\n",
      "non-hierarchical All FixedEpochs DDB mni305\n",
      "non-hierarchical All FixedEpochs Risk lh\n",
      "non-hierarchical All FixedEpochs Risk rh\n",
      "non-hierarchical All FixedEpochs Risk mni305\n",
      "non-hierarchical All FixedEpochs Reward lh\n",
      "non-hierarchical All FixedEpochs Reward rh\n",
      "non-hierarchical All FixedEpochs Reward mni305\n",
      "hierarchical PCA VariableEpochs Control lh\n",
      "hierarchical PCA VariableEpochs Control rh\n",
      "hierarchical PCA VariableEpochs Control mni305\n",
      "hierarchical PCA VariableEpochs DDB lh\n",
      "hierarchical PCA VariableEpochs DDB rh\n",
      "hierarchical PCA VariableEpochs DDB mni305\n",
      "hierarchical PCA VariableEpochs Risk lh\n",
      "hierarchical PCA VariableEpochs Risk rh\n",
      "hierarchical PCA VariableEpochs Risk mni305\n",
      "hierarchical PCA VariableEpochs Reward lh\n",
      "hierarchical PCA VariableEpochs Reward rh\n",
      "hierarchical PCA VariableEpochs Reward mni305\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir,\n",
    "                         concat_sess_dir, thresholds, models,\n",
    "                         spaces, task, prepare_image, conditions_dict)\n",
    "from mne.stats import fdr_correction\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "permutations = np.arange(int(n_permutations/inc)) + 1\n",
    "\n",
    "for model_name, analysis, epochs_type in models:\n",
    "    #\n",
    "    for condition in ['Control'] + conditions_dict[analysis]:\n",
    "        #\n",
    "        FDR, signs = [], []\n",
    "        #\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Compute p-values within spaces.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        #\n",
    "        for n, space in enumerate(spaces):\n",
    "             #\n",
    "            print(model_name, analysis, epochs_type, condition, space)\n",
    "            #\n",
    "            out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                               (version, task, model_name, \n",
    "                                                                analysis, epochs_type,\n",
    "                                                                sm, fd, space, condition)))\n",
    "            obs_f = op.join(out_dir, ('%s.%s.%s.%s.%s.%s.%s.%s.%s_obs.npz' % \n",
    "                                      (version, task, model_name, analysis,\n",
    "                                       epochs_type, sm, fd, space, condition)))\n",
    "            #\n",
    "            ## Load true effects.\n",
    "            npz = np.load(obs_f)\n",
    "            Bmap = npz['Bmap'].squeeze()\n",
    "            Fmap = npz['Fmap'].squeeze()\n",
    "            #\n",
    "            ## Load permutations.\n",
    "            perm_f = op.join(out_dir, ('%s.%s.%s.%s.%s.%s.%s.%s.%s' %\n",
    "                                       (version, task, model_name, analysis,\n",
    "                                        epochs_type, sm, fd, space, condition)) + \n",
    "                                       '_perm-%s.npz')\n",
    "            Pmap = []\n",
    "            for p in permutations:\n",
    "                try:\n",
    "                    npz = np.load(perm_f % p)\n",
    "                    Pmap.append(npz['Fmap'])\n",
    "                except Exception as e:\n",
    "                    print(e, p)  # I was getting bad magic numbers on some file and had to rerun WLS\n",
    "            Pmap = np.concatenate(Pmap, axis=0)\n",
    "            n_permutations, _ = Pmap.shape\n",
    "            #\n",
    "            ## Compute p-values via FWE.\n",
    "            p_values = (Pmap >= Fmap).sum(axis=0) + 1.\n",
    "            p_values /= n_permutations + 1.\n",
    "            FDR.append(p_values)\n",
    "            signs.append(np.sign(Bmap))\n",
    "            #\n",
    "            ## Save maps.\n",
    "            for arr, name in zip([Bmap,Fmap],['beta','F']):\n",
    "                image = prepare_image(arr, space)\n",
    "                image = nib.Nifti1Image(image, np.load(op.join(out_dir, 'affine.npy')))\n",
    "                nib.save(image, op.join(out_dir, '%s.nii.gz' % name))        \n",
    "        #\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Perform FDR corrections.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        #\n",
    "        ## Assemble info.\n",
    "        indices = np.concatenate([np.ones_like(arr) * n for n, arr in enumerate(FDR)])\n",
    "        FDR = np.concatenate(FDR)\n",
    "        signs = np.concatenate(signs)\n",
    "        #\n",
    "        ## Perform FDR correction.\n",
    "        FDR[np.where(signs)] = fdr_correction(FDR[np.where(signs)])[-1]\n",
    "        FDR = -np.log10(FDR) * signs\n",
    "        #\n",
    "        ## Save maps.\n",
    "        for n, space in enumerate(spaces):\n",
    "            out_f = op.join(out_dir, ('%s.%s.%s.%s.%s.%s.%s.%s.%s_fdr' % \n",
    "                                      (version, task, model_name, analysis,\n",
    "                                       epochs_type, sm, fd, space, condition)))\n",
    "            np.save(out_f, FDR[indices==n])\n",
    "            image = prepare_image(FDR[indices==n], space)\n",
    "            image = nib.Nifti1Image(image, np.load(op.join(out_dir,'affine.npy')))\n",
    "            nib.save(image, op.join(out_dir, 'fdr.nii.gz'))\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Second-Level Maps\n",
    "Thresholding clusters such that:\n",
    "* p < 0.05 (FWE corrected, alpha = 0.05)\n",
    "* Surface: clusters > 100mm2\n",
    "* Volume: clusters > 20 contiguous voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T17:04:47.855096Z",
     "start_time": "2019-05-16T17:04:31.811604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lh\n",
      "lh hierarchical DelibMod VariableEpochs\n",
      "lh non-hierarchical DelibMod VariableEpochs\n",
      "lh hierarchical DelibMod FixedEpochs\n",
      "lh non-hierarchical DelibMod FixedEpochs\n",
      "lh parameter Risk VariableEpochs\n",
      "lh parameter Reward VariableEpochs\n",
      "lh parameter Risk FixedEpochs\n",
      "lh parameter Reward FixedEpochs\n",
      "lh hierarchical All VariableEpochs\n",
      "lh hierarchical All FixedEpochs\n",
      "lh non-hierarchical All VariableEpochs\n",
      "lh non-hierarchical All FixedEpochs\n",
      "lh hierarchical PCA VariableEpochs\n",
      "rh\n",
      "rh hierarchical DelibMod VariableEpochs\n",
      "rh non-hierarchical DelibMod VariableEpochs\n",
      "rh hierarchical DelibMod FixedEpochs\n",
      "rh non-hierarchical DelibMod FixedEpochs\n",
      "rh parameter Risk VariableEpochs\n",
      "rh parameter Reward VariableEpochs\n",
      "rh parameter Risk FixedEpochs\n",
      "rh parameter Reward FixedEpochs\n",
      "rh hierarchical All VariableEpochs\n",
      "rh hierarchical All FixedEpochs\n",
      "rh non-hierarchical All VariableEpochs\n",
      "rh non-hierarchical All FixedEpochs\n",
      "rh hierarchical PCA VariableEpochs\n",
      "mni305\n",
      "mni305 hierarchical DelibMod VariableEpochs\n",
      "mni305 non-hierarchical DelibMod VariableEpochs\n",
      "mni305 hierarchical DelibMod FixedEpochs\n",
      "mni305 non-hierarchical DelibMod FixedEpochs\n",
      "mni305 parameter Risk VariableEpochs\n",
      "mni305 parameter Reward VariableEpochs\n",
      "mni305 parameter Risk FixedEpochs\n",
      "mni305 parameter Reward FixedEpochs\n",
      "mni305 hierarchical All VariableEpochs\n",
      "mni305 hierarchical All FixedEpochs\n",
      "mni305 non-hierarchical All VariableEpochs\n",
      "mni305 non-hierarchical All FixedEpochs\n",
      "mni305 hierarchical PCA VariableEpochs\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir,\n",
    "                         concat_sess_dir, thresholds, models,\n",
    "                         spaces, task, prepare_image, fs_dir,\n",
    "                         load_sparse_coo, conditions_dict, psc_threshold)\n",
    "from mne.stats.cluster_level import _find_clusters as find_clusters\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Thresholding parameters.\n",
    "threshold = -np.log10( psc_threshold )\n",
    "min_cluster = dict(lh = 100, rh = 100, mni305 = 20)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "for space in spaces:\n",
    "    #\n",
    "    ## Load connectivity information.\n",
    "    connectivity = load_sparse_coo(op.join(root_dir, 'fmri_second_levels/%s_%s_connectivity.npz' % (version, space)))\n",
    "    #\n",
    "    ## Load mapping information.\n",
    "    npz = np.load(op.join(root_dir, 'fmri_second_levels/%s_%s_connectivity.npz' % (version, space)))\n",
    "    #\n",
    "    if space != 'mni305':\n",
    "        vertices = npz['vertices']\n",
    "        average_area = nib.load(op.join(fs_dir, 'fsaverage', 'surf', '%s.white.avg.area.mgh' % space)).get_data()\n",
    "        average_area = average_area[vertices].squeeze()\n",
    "    #\n",
    "    for model_name, analysis, epochs_type in models:\n",
    "        #\n",
    "        print(space, model_name, analysis, epochs_type)\n",
    "        #\n",
    "        for condition in ['Control'] + conditions_dict[analysis]:\n",
    "            #\n",
    "            ## Load FWE-corrected p-values.\n",
    "            out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                               (version, task, model_name, \n",
    "                                                                analysis, epochs_type,\n",
    "                                                                sm, fd, space, condition)))\n",
    "            fwe_f = op.join(out_dir, ('%s.%s.%s.%s.%s.%s.%s.%s.%s_fwe.npy' % \n",
    "                                      (version, task, model_name, analysis,\n",
    "                                       epochs_type, sm, fd, space, condition)))\n",
    "            fwe = np.load(fwe_f)\n",
    "            #\n",
    "            ## Find clusters.\n",
    "            include = np.where(fwe, True, False)\n",
    "            clusters, sums = find_clusters(fwe, threshold, tail=0, connectivity=connectivity, \n",
    "                                           include=include, t_power=0)\n",
    "            #\n",
    "            ## Compute areas.\n",
    "            if space == 'mni305': \n",
    "                cluster_sums = sums\n",
    "            else:\n",
    "                cluster_sums = np.array([average_area[c].sum() for c in clusters])\n",
    "            #\n",
    "            ## Threshold.\n",
    "            try:\n",
    "                survival_ix = np.concatenate([c for c, s in zip(clusters, cluster_sums) if s > min_cluster[space]])\n",
    "                fwe[~np.in1d(np.arange(fwe.shape[0]), survival_ix)] = 0\n",
    "            except ValueError:\n",
    "                #print('No clusters', space, model_name, analysis, epochs_type, condition)\n",
    "                fwe = np.zeros_like(fwe)\n",
    "                fwe[0] = 1; fwe[-1] = 1 # pysurfer bug: https://github.com/nipy/PySurfer/issues/267\n",
    "            #\n",
    "            ## Save.\n",
    "            image = prepare_image(fwe, space)\n",
    "            image = nib.Nifti1Image(image, np.load(op.join(op.dirname(fwe_f),'affine.npy')))\n",
    "            nib.save(image, op.join(op.dirname(fwe_f), 'fwe_thresh_%s.nii.gz' % psc_threshold))\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Percent Signal Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T17:05:44.122244Z",
     "start_time": "2019-05-16T17:04:55.480238Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lh hierarchical DelibMod VariableEpochs\n",
      "lh non-hierarchical DelibMod VariableEpochs\n",
      "lh hierarchical DelibMod FixedEpochs\n",
      "lh non-hierarchical DelibMod FixedEpochs\n",
      "lh parameter Risk VariableEpochs\n",
      "lh parameter Reward VariableEpochs\n",
      "lh parameter Risk FixedEpochs\n",
      "lh parameter Reward FixedEpochs\n",
      "lh hierarchical All VariableEpochs\n",
      "lh hierarchical All FixedEpochs\n",
      "lh non-hierarchical All VariableEpochs\n",
      "lh non-hierarchical All FixedEpochs\n",
      "lh hierarchical PCA VariableEpochs\n",
      "rh hierarchical DelibMod VariableEpochs\n",
      "rh non-hierarchical DelibMod VariableEpochs\n",
      "rh hierarchical DelibMod FixedEpochs\n",
      "rh non-hierarchical DelibMod FixedEpochs\n",
      "rh parameter Risk VariableEpochs\n",
      "rh parameter Reward VariableEpochs\n",
      "rh parameter Risk FixedEpochs\n",
      "rh parameter Reward FixedEpochs\n",
      "rh hierarchical All VariableEpochs\n",
      "rh hierarchical All FixedEpochs\n",
      "rh non-hierarchical All VariableEpochs\n",
      "rh non-hierarchical All FixedEpochs\n",
      "rh hierarchical PCA VariableEpochs\n",
      "mni305 hierarchical DelibMod VariableEpochs\n",
      "mni305 non-hierarchical DelibMod VariableEpochs\n",
      "mni305 hierarchical DelibMod FixedEpochs\n",
      "mni305 non-hierarchical DelibMod FixedEpochs\n",
      "mni305 parameter Risk VariableEpochs\n",
      "mni305 parameter Reward VariableEpochs\n",
      "mni305 parameter Risk FixedEpochs\n",
      "mni305 parameter Reward FixedEpochs\n",
      "mni305 hierarchical All VariableEpochs\n",
      "mni305 hierarchical All FixedEpochs\n",
      "mni305 non-hierarchical All VariableEpochs\n",
      "mni305 non-hierarchical All FixedEpochs\n",
      "mni305 hierarchical PCA VariableEpochs\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir,\n",
    "                         concat_sess_dir, thresholds, models,\n",
    "                         spaces, task, session, prepare_image, fs_dir,\n",
    "                         load_sparse_coo, psc_threshold, subjects,\n",
    "                         conditions_dict, plt)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main Loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load average signal.\n",
    "mean_signal = np.load(op.join(root_dir, 'fmri_second_levels/%s_mean_signal.npz' % version))\n",
    "\n",
    "for space in spaces:\n",
    "    #\n",
    "    ## Assemble design matrices.\n",
    "    subj_dir = op.join(root_dir, 'fmri_first_levels', '%s', '%s_%03d' % (task, session))\n",
    "    for model_name, analysis, epochs_type in models:\n",
    "        #\n",
    "        print(space, model_name, analysis, epochs_type)\n",
    "        #\n",
    "        X_f = op.join(subj_dir, \n",
    "                      ('%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                       (version, task, model_name, \n",
    "                        analysis, epochs_type,\n",
    "                        sm, fd, space)), 'X.dat')\n",
    "        scale_factors = np.array([np.loadtxt(X_f % subject).max(axis=0)[:(len(conditions_dict[analysis])+1)]\n",
    "                                 for subject in subjects]).T\n",
    "        #\n",
    "        for n, condition in enumerate(['Control'] + conditions_dict[analysis]):\n",
    "            #\n",
    "            ## Load first levels.\n",
    "            out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                               (version, task, model_name,\n",
    "                                                                analysis, epochs_type,\n",
    "                                                                sm, fd, space, condition)))\n",
    "            ces = np.load(op.join(out_dir, 'first_levels.npz'))['ces']\n",
    "            #\n",
    "            ## Compute PSC (Pernet 2014, Frontiers in Neuroscience).\n",
    "            ms = np.where(mean_signal[space], mean_signal[space], np.inf).T\n",
    "            psc = np.divide(ces * scale_factors[n] * 100., ms)\n",
    "            psc = prepare_image(psc.mean(axis=1), space)\n",
    "            #\n",
    "            ## Mask image.\n",
    "            fwe = nib.load(op.join(out_dir, 'fwe_thresh_%s.nii.gz' % psc_threshold)).get_data()\n",
    "            psc *= np.where(fwe, 1, 0)\n",
    "            #\n",
    "            ## Save.\n",
    "            image = nib.Nifti1Image(psc, np.load(op.join(out_dir, 'affine.npy')))\n",
    "            nib.save(image, op.join(out_dir, 'psc.nii.gz'))\n",
    "        \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T17:08:46.841078Z",
     "start_time": "2019-05-16T17:06:32.188696Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lh hierarchical DelibMod VariableEpochs Control\n",
      "lh hierarchical DelibMod VariableEpochs DDB\n",
      "lh non-hierarchical DelibMod VariableEpochs Control\n",
      "lh non-hierarchical DelibMod VariableEpochs DDB\n",
      "lh hierarchical DelibMod FixedEpochs Control\n",
      "lh hierarchical DelibMod FixedEpochs DDB\n",
      "lh non-hierarchical DelibMod FixedEpochs Control\n",
      "lh non-hierarchical DelibMod FixedEpochs DDB\n",
      "lh parameter Risk VariableEpochs Control\n",
      "lh parameter Risk VariableEpochs Risk\n",
      "lh parameter Reward VariableEpochs Control\n",
      "lh parameter Reward VariableEpochs Reward\n",
      "lh parameter Risk FixedEpochs Control\n",
      "lh parameter Risk FixedEpochs Risk\n",
      "lh parameter Reward FixedEpochs Control\n",
      "lh parameter Reward FixedEpochs Reward\n",
      "lh hierarchical All VariableEpochs Control\n",
      "lh hierarchical All VariableEpochs DDB\n",
      "lh hierarchical All VariableEpochs Risk\n",
      "lh hierarchical All VariableEpochs Reward\n",
      "lh hierarchical All FixedEpochs Control\n",
      "lh hierarchical All FixedEpochs DDB\n",
      "lh hierarchical All FixedEpochs Risk\n",
      "lh hierarchical All FixedEpochs Reward\n",
      "lh non-hierarchical All VariableEpochs Control\n",
      "lh non-hierarchical All VariableEpochs DDB\n",
      "lh non-hierarchical All VariableEpochs Risk\n",
      "lh non-hierarchical All VariableEpochs Reward\n",
      "lh non-hierarchical All FixedEpochs Control\n",
      "lh non-hierarchical All FixedEpochs DDB\n",
      "lh non-hierarchical All FixedEpochs Risk\n",
      "lh non-hierarchical All FixedEpochs Reward\n",
      "lh hierarchical PCA VariableEpochs Control\n",
      "lh hierarchical PCA VariableEpochs DDB\n",
      "lh hierarchical PCA VariableEpochs Risk\n",
      "lh hierarchical PCA VariableEpochs Reward\n",
      "rh hierarchical DelibMod VariableEpochs Control\n",
      "rh hierarchical DelibMod VariableEpochs DDB\n",
      "rh non-hierarchical DelibMod VariableEpochs Control\n",
      "rh non-hierarchical DelibMod VariableEpochs DDB\n",
      "rh hierarchical DelibMod FixedEpochs Control\n",
      "rh hierarchical DelibMod FixedEpochs DDB\n",
      "rh non-hierarchical DelibMod FixedEpochs Control\n",
      "rh non-hierarchical DelibMod FixedEpochs DDB\n",
      "rh parameter Risk VariableEpochs Control\n",
      "rh parameter Risk VariableEpochs Risk\n",
      "rh parameter Reward VariableEpochs Control\n",
      "rh parameter Reward VariableEpochs Reward\n",
      "rh parameter Risk FixedEpochs Control\n",
      "rh parameter Risk FixedEpochs Risk\n",
      "rh parameter Reward FixedEpochs Control\n",
      "rh parameter Reward FixedEpochs Reward\n",
      "rh hierarchical All VariableEpochs Control\n",
      "rh hierarchical All VariableEpochs DDB\n",
      "rh hierarchical All VariableEpochs Risk\n",
      "rh hierarchical All VariableEpochs Reward\n",
      "rh hierarchical All FixedEpochs Control\n",
      "rh hierarchical All FixedEpochs DDB\n",
      "rh hierarchical All FixedEpochs Risk\n",
      "rh hierarchical All FixedEpochs Reward\n",
      "rh non-hierarchical All VariableEpochs Control\n",
      "rh non-hierarchical All VariableEpochs DDB\n",
      "rh non-hierarchical All VariableEpochs Risk\n",
      "rh non-hierarchical All VariableEpochs Reward\n",
      "rh non-hierarchical All FixedEpochs Control\n",
      "rh non-hierarchical All FixedEpochs DDB\n",
      "rh non-hierarchical All FixedEpochs Risk\n",
      "rh non-hierarchical All FixedEpochs Reward\n",
      "rh hierarchical PCA VariableEpochs Control\n",
      "rh hierarchical PCA VariableEpochs DDB\n",
      "rh hierarchical PCA VariableEpochs Risk\n",
      "rh hierarchical PCA VariableEpochs Reward\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir,\n",
    "                         concat_sess_dir, thresholds, models,\n",
    "                         spaces, task, prepare_image, fs_dir,\n",
    "                         load_sparse_coo, subjects, img_dir,\n",
    "                         overlay, surface, conditions_dict,\n",
    "                         psc_threshold)\n",
    "from surfer import Brain\n",
    "\n",
    "threshold = -np.log10( psc_threshold )\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plot.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "for hemi in ['lh', 'rh']: \n",
    "    #\n",
    "    for model_name, analysis, epochs_type in models:\n",
    "        #\n",
    "        for condition in ['Control'] + conditions_dict[analysis]:\n",
    "            #\n",
    "            print(hemi, model_name, analysis, epochs_type, condition)\n",
    "            #\n",
    "            out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                               (version, task, model_name,\n",
    "                                                                analysis, epochs_type,\n",
    "                                                                sm, fd, hemi, condition)))\n",
    "            fn = op.join(out_dir, '%s.nii.gz' % overlay)\n",
    "            #\n",
    "            for view in ['lateral', 'medial']:\n",
    "                #\n",
    "                brain = Brain('fsaverage', hemi, surface, subjects_dir=fs_dir)\n",
    "                try: \n",
    "                    brain.add_overlay(fn, min=0.04, max=2.5, sign=\"pos\")\n",
    "                except Exception as e: \n",
    "                    print(e)\n",
    "                    continue\n",
    "                brain.show_view(view=view)\n",
    "                od = op.join(img_dir, overlay, surface, \n",
    "                             ('%s.%s.%s.%s.%s.%s.%s.' % \n",
    "                             (version, task, model_name, \n",
    "                              analysis, epochs_type, sm, fd)))\n",
    "                if not op.isdir(od): \n",
    "                    os.makedirs(od)\n",
    "                out_f = op.join(od, '%s.%s.%s.png' % (condition, hemi, view))\n",
    "                Brain.save_image(brain, out_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute surface summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T19:03:26.740856Z",
     "start_time": "2019-05-16T19:01:29.209803Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchical DelibMod VariableEpochs Control lh\n",
      "hierarchical DelibMod VariableEpochs Control rh\n",
      "hierarchical DelibMod VariableEpochs DDB lh\n",
      "hierarchical DelibMod VariableEpochs DDB rh\n",
      "non-hierarchical DelibMod VariableEpochs Control lh\n",
      "non-hierarchical DelibMod VariableEpochs Control rh\n",
      "non-hierarchical DelibMod VariableEpochs DDB lh\n",
      "non-hierarchical DelibMod VariableEpochs DDB rh\n",
      "hierarchical DelibMod FixedEpochs Control lh\n",
      "hierarchical DelibMod FixedEpochs Control rh\n",
      "hierarchical DelibMod FixedEpochs DDB lh\n",
      "hierarchical DelibMod FixedEpochs DDB rh\n",
      "non-hierarchical DelibMod FixedEpochs Control lh\n",
      "non-hierarchical DelibMod FixedEpochs Control rh\n",
      "non-hierarchical DelibMod FixedEpochs DDB lh\n",
      "non-hierarchical DelibMod FixedEpochs DDB rh\n",
      "parameter Risk VariableEpochs Control lh\n",
      "parameter Risk VariableEpochs Control rh\n",
      "parameter Risk VariableEpochs Risk lh\n",
      "parameter Risk VariableEpochs Risk rh\n",
      "parameter Reward VariableEpochs Control lh\n",
      "parameter Reward VariableEpochs Control rh\n",
      "parameter Reward VariableEpochs Reward lh\n",
      "parameter Reward VariableEpochs Reward rh\n",
      "parameter Risk FixedEpochs Control lh\n",
      "parameter Risk FixedEpochs Control rh\n",
      "parameter Risk FixedEpochs Risk lh\n",
      "parameter Risk FixedEpochs Risk rh\n",
      "parameter Reward FixedEpochs Control lh\n",
      "parameter Reward FixedEpochs Control rh\n",
      "parameter Reward FixedEpochs Reward lh\n",
      "parameter Reward FixedEpochs Reward rh\n",
      "hierarchical All VariableEpochs Control lh\n",
      "hierarchical All VariableEpochs Control rh\n",
      "hierarchical All VariableEpochs DDB lh\n",
      "hierarchical All VariableEpochs DDB rh\n",
      "hierarchical All VariableEpochs Risk lh\n",
      "hierarchical All VariableEpochs Risk rh\n",
      "hierarchical All VariableEpochs Reward lh\n",
      "hierarchical All VariableEpochs Reward rh\n",
      "hierarchical All FixedEpochs Control lh\n",
      "hierarchical All FixedEpochs Control rh\n",
      "hierarchical All FixedEpochs DDB lh\n",
      "hierarchical All FixedEpochs DDB rh\n",
      "hierarchical All FixedEpochs Risk lh\n",
      "hierarchical All FixedEpochs Risk rh\n",
      "hierarchical All FixedEpochs Reward lh\n",
      "hierarchical All FixedEpochs Reward rh\n",
      "non-hierarchical All VariableEpochs Control lh\n",
      "non-hierarchical All VariableEpochs Control rh\n",
      "non-hierarchical All VariableEpochs DDB lh\n",
      "non-hierarchical All VariableEpochs DDB rh\n",
      "non-hierarchical All VariableEpochs Risk lh\n",
      "non-hierarchical All VariableEpochs Risk rh\n",
      "non-hierarchical All VariableEpochs Reward lh\n",
      "non-hierarchical All VariableEpochs Reward rh\n",
      "non-hierarchical All FixedEpochs Control lh\n",
      "non-hierarchical All FixedEpochs Control rh\n",
      "non-hierarchical All FixedEpochs DDB lh\n",
      "non-hierarchical All FixedEpochs DDB rh\n",
      "non-hierarchical All FixedEpochs Risk lh\n",
      "non-hierarchical All FixedEpochs Risk rh\n",
      "non-hierarchical All FixedEpochs Reward lh\n",
      "non-hierarchical All FixedEpochs Reward rh\n",
      "hierarchical PCA VariableEpochs Control lh\n",
      "hierarchical PCA VariableEpochs Control rh\n",
      "hierarchical PCA VariableEpochs DDB lh\n",
      "hierarchical PCA VariableEpochs DDB rh\n",
      "hierarchical PCA VariableEpochs Risk lh\n",
      "hierarchical PCA VariableEpochs Risk rh\n",
      "hierarchical PCA VariableEpochs Reward lh\n",
      "hierarchical PCA VariableEpochs Reward rh\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir,\n",
    "                         concat_sess_dir, thresholds, models,\n",
    "                         spaces, task, prepare_image, fs_dir,\n",
    "                         load_sparse_coo, subjects, img_dir,\n",
    "                         overlay, surface, psc_threshold, conditions_dict,\n",
    "                         label_dir, rois)\n",
    "from mne import Label, read_label, grow_labels, vertex_to_mni, set_log_level\n",
    "set_log_level(verbose=False)\n",
    "\n",
    "\n",
    "threshold = -np.log10( psc_threshold )\n",
    "\n",
    "## ROI parameters.\n",
    "extent = 10 #mm\n",
    "grow = False\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "for model_name, analysis, epochs_type in models:\n",
    "    #\n",
    "    for condition in ['Control'] + conditions_dict[analysis]:\n",
    "        #\n",
    "        for hemi in ['lh', 'rh']:\n",
    "            #\n",
    "            print(model_name, analysis, epochs_type, condition, hemi)\n",
    "            #\n",
    "            out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                               (version, task, model_name,\n",
    "                                                                analysis, epochs_type,\n",
    "                                                                sm, fd, hemi, condition)))\n",
    "            #label_dir = op.join(root_dir, 'fmri_second_levels/labels/', 'seeds_%s' % task)\n",
    "            #labels = sorted([f for f in os.listdir(label_dir) if not f.startswith('fig') and f.endswith('label')])\n",
    "            #\n",
    "            fmni = open(op.join(label_dir, ('surface_mni2.%s.%s.%s.%s.%s.%s.%s.%s.%s.csv' % \n",
    "                                            (version, task, model_name,\n",
    "                                             analysis, epochs_type,\n",
    "                                             sm, fd, hemi, condition))), 'w')\n",
    "            fmni.write(','.join(['Label', 'V', 'X', 'Y', 'Z', 'PSC', 'F', 'p']) + '\\n')\n",
    "            #\n",
    "            for roi in rois:\n",
    "                #\n",
    "                label = read_label(op.join(label_dir, '%s-%s.label' % (roi, hemi)))\n",
    "                #\n",
    "                ## Load accompanying overlay.\n",
    "                f = op.join(out_dir, 'psc.nii.gz')\n",
    "                overlay = nib.load(f).get_data().squeeze()\n",
    "                #\n",
    "                ## Find maximum vertex.\n",
    "                ix = np.argmax(overlay[label.vertices])\n",
    "                v = label.vertices[ix]\n",
    "                #\n",
    "                ## Extract MNI coordinates.\n",
    "                x,y,z = vertex_to_mni(v, 0 if hemi == 'lh' else 1, 'fsaverage', fs_dir)[0]\n",
    "                #\n",
    "                ## Extract PSC, F-scores, p-values.\n",
    "                f = op.join(out_dir, 'psc.nii.gz')\n",
    "                psc = nib.load(f).get_data().squeeze()[v]\n",
    "                #\n",
    "                f = op.join(out_dir, 'F.nii.gz')\n",
    "                F = nib.load(f).get_data().squeeze()[v]\n",
    "                #\n",
    "                f = op.join(out_dir, 'fwe_thresh_%.3f.nii.gz' % threshold)\n",
    "                p = nib.load(f).get_data().squeeze()[v]\n",
    "                #\n",
    "                ## Write information.\n",
    "                fmni.write('%s-%s,%s,%0.0f,%0.0f,%0.0f,%0.2f,%0.2f,%0.6f\\n' % (roi, hemi, v, x, y, z, psc, F, 10.**-p))\n",
    "                #\n",
    "                if grow:\n",
    "                    ## Grow label.\n",
    "                    label = grow_labels('fsaverage', v, extent, 0 if hemi=='lh' else 1, subjects_dir=fs_dir,\n",
    "                                        names='fig_%s-%s' % (roi, hemi), surface='pial')[0]\n",
    "                    #\n",
    "                    ## Ensure label is within actiation. Save.\n",
    "                    ix = np.in1d(label.vertices, np.where(overlay)[0])\n",
    "                    label.pos = label.pos[ix]\n",
    "                    label.values = label.values[ix]\n",
    "                    label.vertices = label.vertices[ix]\n",
    "                    label.save('%s/%s.label' % (out_label_dir, label.name))\n",
    "\n",
    "fmni.close()\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute volume summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T19:06:10.896287Z",
     "start_time": "2019-05-16T19:06:04.119489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchical DelibMod VariableEpochs Control\n",
      "hierarchical DelibMod VariableEpochs DDB\n",
      "non-hierarchical DelibMod VariableEpochs Control\n",
      "non-hierarchical DelibMod VariableEpochs DDB\n",
      "hierarchical DelibMod FixedEpochs Control\n",
      "hierarchical DelibMod FixedEpochs DDB\n",
      "non-hierarchical DelibMod FixedEpochs Control\n",
      "non-hierarchical DelibMod FixedEpochs DDB\n",
      "parameter Risk VariableEpochs Control\n",
      "parameter Risk VariableEpochs Risk\n",
      "parameter Reward VariableEpochs Control\n",
      "parameter Reward VariableEpochs Reward\n",
      "parameter Risk FixedEpochs Control\n",
      "parameter Risk FixedEpochs Risk\n",
      "parameter Reward FixedEpochs Control\n",
      "parameter Reward FixedEpochs Reward\n",
      "hierarchical All VariableEpochs Control\n",
      "hierarchical All VariableEpochs DDB\n",
      "hierarchical All VariableEpochs Risk\n",
      "hierarchical All VariableEpochs Reward\n",
      "hierarchical All FixedEpochs Control\n",
      "hierarchical All FixedEpochs DDB\n",
      "hierarchical All FixedEpochs Risk\n",
      "hierarchical All FixedEpochs Reward\n",
      "non-hierarchical All VariableEpochs Control\n",
      "non-hierarchical All VariableEpochs DDB\n",
      "non-hierarchical All VariableEpochs Risk\n",
      "non-hierarchical All VariableEpochs Reward\n",
      "non-hierarchical All FixedEpochs Control\n",
      "non-hierarchical All FixedEpochs DDB\n",
      "non-hierarchical All FixedEpochs Risk\n",
      "non-hierarchical All FixedEpochs Reward\n",
      "hierarchical PCA VariableEpochs Control\n",
      "hierarchical PCA VariableEpochs DDB\n",
      "hierarchical PCA VariableEpochs Risk\n",
      "hierarchical PCA VariableEpochs Reward\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir,\n",
    "                         concat_sess_dir, thresholds, models,\n",
    "                         spaces, task, prepare_image, fs_dir,\n",
    "                         load_sparse_coo, subjects, img_dir, \n",
    "                         conditions_dict, psc_threshold, \n",
    "                         label_dir)\n",
    "from nibabel.affines import apply_affine\n",
    "\n",
    "space = 'mni305'\n",
    "threshold = -np.log10( psc_threshold )\n",
    "\n",
    "## ROI parameters.\n",
    "extent = 6 #mm\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "for model_name, analysis, epochs_type in models:\n",
    "    #\n",
    "    for condition in ['Control'] + conditions_dict[analysis]:\n",
    "        #\n",
    "        print(model_name, analysis, epochs_type, condition)\n",
    "        #\n",
    "        out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                           (version, task, model_name,\n",
    "                                                            analysis, epochs_type,\n",
    "                                                            sm, fd, space, condition)))\n",
    "        ## Initialize statistics file.\n",
    "        fmni = open(op.join(label_dir, ('volume_mni2.%s.%s.%s.%s.%s.%s.%s.%s.%s.csv' % \n",
    "                                        (version, task, model_name,\n",
    "                                         analysis, epochs_type,\n",
    "                                         sm, fd, hemi, condition))), 'w')\n",
    "        fmni.write(','.join(['Label','cX','cY','cZ','X','Y','Z','PSC','F','p']) + '\\n')\n",
    "        #\n",
    "        ## Load data. \n",
    "        npz = np.load(op.join(root_dir, 'fmri_second_levels/%s_mni305_connectivity.npz' % version))\n",
    "        affine = np.load(op.join(out_dir, 'affine.npy'))\n",
    "        obj = nib.load(op.join(out_dir, 'psc.nii.gz'))\n",
    "        #\n",
    "        overlay = obj.get_data().squeeze()\n",
    "        Fval = nib.load(op.join(out_dir, 'F.nii.gz')).get_data().squeeze()\n",
    "        pval = nib.load(op.join(out_dir, 'fwe_thresh_%.3f.nii.gz' % threshold)).get_data().squeeze()\n",
    "        #\n",
    "        rois = ['Left-Caudate', 'Left-Putamen', 'Left-Hippocampus',\n",
    "                'Right-Caudate', 'Right-Putamen', 'Right-Hippocampus']\n",
    "        for roi in rois:\n",
    "            #\n",
    "            ## Extract activated voxels in ROI.\n",
    "            voxels = npz['voxels'][npz['names'] == roi]\n",
    "            voxels = voxels[np.where(overlay[tuple([arr for arr in voxels.T])])]\n",
    "            if voxels.shape[0] == 0:\n",
    "                continue\n",
    "            #\n",
    "            ## Find maximally activated voxel.\n",
    "            ix = np.argmax(overlay[tuple([arr for arr in voxels.T])])\n",
    "            center = voxels[ix]\n",
    "            i,j,k = center\n",
    "            #\n",
    "            ## Get MNI coordinates.\n",
    "            x,y,z = apply_affine(affine, center)\n",
    "            #\n",
    "            ## Extract max values.\n",
    "            psc = overlay[i,j,k]\n",
    "            F = Fval[i,j,k]\n",
    "            p = pval[i,j,k]\n",
    "            #\n",
    "            ## Write to file.\n",
    "            fmni.write('%s,%0.0d,%0.0d,%0.0d,%0.0d,%0.2d,%0.2d,%0.2f,%0.2f,%0.6f\\n' % (roi, i, j, k, x, y, z, psc, F, 10.**-p))\n",
    "            #\n",
    "            ## Create sphere: find all voxels within extent.\n",
    "            dist = [np.linalg.norm( np.diff( apply_affine(affine,np.vstack([center,v])), axis=0 ) ) for v in voxels]\n",
    "            ix = np.where(np.array(dist)<=extent)\n",
    "            sphere = voxels[ix]\n",
    "            #\n",
    "            ## Save.\n",
    "            #hemi, roi = roi.split('-')\n",
    "            #if hemi.startswith('L'): name = '%s-lh' %roi.lower()\n",
    "            #else: name = '%s-rh' %roi.lower()\n",
    "            #np.save(op.join(out_dir, name), sphere)\n",
    "        fmni.close()\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-hoc F-statistic Fix\n",
    "Sam realized very late in the game he should have been saving out the pre-TFCE F-statistics. Fortunately these can be recomputed using the WLS code sans TFCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T19:31:13.905828Z",
     "start_time": "2019-05-16T19:22:05.618790Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/autofs/space/karima_001/users/alex/software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from my_settings import (os, op, np, root_dir, version, n_subj, nib, \n",
    "                         sm, fd, tr, n_acq, subjects, subj_dir, read_csv,\n",
    "                         concat_sess_dir, thresholds, models,\n",
    "                         spaces, task, prepare_image, fs_dir,\n",
    "                         load_sparse_coo, subjects, img_dir, wls,\n",
    "                         X, n_pred, conditions_dict, label_dir)\n",
    "\n",
    "for model_name, analysis, epochs_type in models:\n",
    "    #\n",
    "    for condition in ['Control'] + conditions_dict[analysis]:\n",
    "        #\n",
    "        for space in spaces:\n",
    "            #\n",
    "            print(model_name, analysis, epochs_type, condition, space)\n",
    "            #\n",
    "            out_dir = op.join(root_dir, 'fmri_second_levels', ('%s.%s.%s.%s.%s.%s.%s.%s.%s' % \n",
    "                                                               (version, task, model_name,\n",
    "                                                                analysis, epochs_type,\n",
    "                                                                sm, fd, space, condition)))\n",
    "            #\n",
    "            ## Load data.\n",
    "            npz = np.load(op.join(out_dir, 'first_levels.npz'))\n",
    "            ces = npz['ces']\n",
    "            cesvar = np.abs( 1. / npz['cesvar'] )\n",
    "            #\n",
    "            ## Define indices.\n",
    "            connectivity = load_sparse_coo(op.join(root_dir, 'fmri_second_levels', '%s_%s_connectivity.npz' % (version, space)))\n",
    "            index,  = np.where(~np.isinf(cesvar).sum(axis=1).astype(bool))\n",
    "            include = ~np.isinf(cesvar).sum(axis=1).astype(bool)\n",
    "            #\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Setup for permutation testing.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            #\n",
    "            sign_flips = np.ones((1,n_subj))\n",
    "            n_shuffles = sign_flips.shape[0]\n",
    "            #\n",
    "            ## Preallocate arrays for results.\n",
    "            shape = [n_shuffles] + list(ces.shape[:-1])\n",
    "            Bmap = np.zeros(shape)\n",
    "            Fmap = np.zeros(shape)\n",
    "            #\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Main loop.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            #\n",
    "            ## Loop it!\n",
    "            for n, sf in enumerate(sign_flips):\n",
    "                #\n",
    "                #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "                ### Compute statistics.\n",
    "                #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "                #\n",
    "                for m in index:\n",
    "                    #\n",
    "                    ## Update variables.\n",
    "                    W = np.diag(cesvar[m])\n",
    "                    Y = ces[m]\n",
    "                    #\n",
    "                    ## Permute values.\n",
    "                    ## See Winkler et al. (2014), pg. 385\n",
    "                    ## To compute Hat Matrix, see: https://en.wikipedia.org/wiki/Projection_matrix and \n",
    "                    Z = X[:,1:]\n",
    "                    ZZ = Z.dot( np.linalg.inv( Z.T.dot(W).dot(Z) ) ).dot(Z.T).dot(W)\n",
    "                    Rz = np.identity(n_subj) - ZZ\n",
    "                    Y = np.diag(sf).dot(Rz).dot(Y)\n",
    "                    #\n",
    "                    ## Perform WLS.\n",
    "                    Bmap[n,m], Fmap[n,m] = wls(X,Y,W) \n",
    "            #\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Save results.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#  \n",
    "            #\n",
    "            ## Translate array back into proper space.\n",
    "            image = prepare_image(Fmap.squeeze(), space).squeeze()\n",
    "            #\n",
    "            ## Load in results table.\n",
    "            resultsf = op.join(label_dir, '%s' + ('_mni2.%s.%s.%s.%s.%s.%s.%s.%s.%s.csv' % \n",
    "                                                  (version, task, model_name,\n",
    "                                                   analysis, epochs_type,\n",
    "                                                   sm, fd, hemi, condition)))\n",
    "            if space == 'mni305':\n",
    "                results = read_csv(resultsf % 'volume')\n",
    "                fscores = [image[i,j,k] for i,j,k in results[['cX','cY','cZ']].values]\n",
    "                results['Fpre'] = fscores\n",
    "                results.to_csv(resultsf % 'fstat_volume', index=False)\n",
    "            else:\n",
    "                results = read_csv(resultsf % 'surface')\n",
    "                if not 'Fpre' in results.columns: results['Fpre'] = np.nan\n",
    "                vertices = results.loc[[True if label.endswith(space) else False for label in results.Label],'V'].values\n",
    "                for v in vertices: results.loc[results.V==v,'Fpre'] = image[v]\n",
    "                results.to_csv(resultsf % 'fstat_surface', index=False)\n",
    "    \n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "343px",
    "left": "2px",
    "right": "1513px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc_position": {
   "height": "767px",
   "left": "0px",
   "right": "1317px",
   "top": "106px",
   "width": "205px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
