{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yarkoni Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from scipy.special import gammaln\n",
    "plt.ion()\n",
    "sns.set_style(style='white')\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "def spm_hrf(RT, P=None, fMRI_T=16):\n",
    "    p = np.array([6, 16, 1, 1, 6, 0, 32], dtype=float)\n",
    "    if P is not None:\n",
    "        p[0:len(P)] = P\n",
    "\n",
    "    _spm_Gpdf = lambda x, h, l: np.exp(h * np.log(l) + (h - 1) * np.log(x) - (l * x) - gammaln(h))\n",
    "    # modelled hemodynamic response function - {mixture of Gammas}\n",
    "    dt = RT / float(fMRI_T)\n",
    "    u = np.arange(0, int(p[6] / dt + 1)) - p[5] / dt\n",
    "    with np.errstate(divide='ignore'):  # Known division-by-zero\n",
    "        hrf = _spm_Gpdf(u, p[0] / p[2], dt / p[2]) - _spm_Gpdf(u, p[1] / p[3],\n",
    "                                                               dt / p[3]) / p[4]\n",
    "    idx = np.arange(0, int((p[6] / RT) + 1)) * fMRI_T\n",
    "    hrf = hrf[idx]\n",
    "    hrf = hrf / np.sum(hrf)\n",
    "    return hrf\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Generate sample data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Initialize HRF.\n",
    "sfreq = 1e-1\n",
    "hrf = spm_hrf(sfreq)\n",
    "\n",
    "## Construct boxcars.\n",
    "times = np.arange(0,2+sfreq,sfreq)\n",
    "boxcars = np.zeros((4,times.shape[0]))\n",
    "\n",
    "mask = (times >= 0.05) & (times <= 1)\n",
    "boxcars[0,mask] += 1.00    # Low conflict\n",
    "boxcars[1,mask] += 1.25    # High conflict\n",
    "boxcars[2,mask] += 1.00    # Fast RT\n",
    "mask = (times >= 0.05) & (times <= 1.25)\n",
    "boxcars[3,mask] += 1.00    # Slow RT\n",
    "\n",
    "## Construct BOLDF response.\n",
    "BOLD = np.apply_along_axis(np.convolve, 1, boxcars, hrf)\n",
    "bold_times = np.arange(0,BOLD.shape[-1]*sfreq,sfreq)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "colors = ['#377eb8','#4daf4a']\n",
    "lw = 2.5\n",
    "\n",
    "## Amplitude differences.\n",
    "ax = plt.subplot2grid((2,3),(0,0))\n",
    "for n, color in zip([0,1],colors):\n",
    "    ax.plot(times, boxcars[n], lw=lw, color=color, alpha=0.7)\n",
    "ax.hlines(0,-0.1,2,linestyle='--',color='k',alpha=0.4)\n",
    "ax.set_xlim(-0.1,2)\n",
    "ax.set_ylim(-0.1,1.5)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('Time (s)', fontsize=16)\n",
    "ax.set_title('A. Differences in amplitude of physiological processes', \n",
    "             loc='left', weight='bold', fontsize=18)\n",
    "\n",
    "ax = plt.subplot2grid((2,3),(0,1),colspan=2)\n",
    "for n, color, label in zip([0,1],colors,['Low Effort','High Effort']):\n",
    "    ax.plot(bold_times, BOLD[n], lw=lw, color=color, alpha=0.7, label=label)\n",
    "ax.hlines(0,-0.1,16,linestyle='--',color='k',alpha=0.4)\n",
    "ax.set_xlim(-0.1,16)\n",
    "ax.set_xticks([0,5,10,15])\n",
    "ax.set_ylim(-0.02,0.3)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('Time (s)', fontsize=16)\n",
    "ax.legend(loc=1, frameon=False, fontsize=14)\n",
    "\n",
    "## Duration differences.\n",
    "ax = plt.subplot2grid((2,3),(1,0))\n",
    "for n, color in zip([2,3],colors):\n",
    "    ax.plot(times, boxcars[n], lw=lw, color=color, alpha=0.7)\n",
    "ax.hlines(0,-0.1,2,linestyle='--',color='k',alpha=0.4)\n",
    "ax.set_xlim(-0.1,2)\n",
    "ax.set_ylim(-0.1,1.5)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('Time (s)', fontsize=16)\n",
    "ax.set_title('B. Differences in duration of physiological processes', \n",
    "             loc='left', weight='bold', fontsize=18)\n",
    "\n",
    "\n",
    "ax = plt.subplot2grid((2,3),(1,1),colspan=2)\n",
    "for n, color, label in zip([2,3],colors,['Fast RT','Long RT']):\n",
    "    ax.plot(bold_times, BOLD[n], lw=lw, color=color, alpha=0.7, label=label)\n",
    "ax.hlines(0,-0.1,16,linestyle='--',color='k',alpha=0.4)\n",
    "ax.set_xlim(-0.1,16)\n",
    "ax.set_xlim(0,16)\n",
    "ax.set_xticks([0,5,10,15])\n",
    "ax.set_ylim(-0.02,0.3)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('Time (s)', fontsize=16)\n",
    "ax.legend(loc=1, frameon=False, fontsize=14)\n",
    "\n",
    "plt.subplots_adjust(left=0.02, right=0.98, bottom=0.125, hspace=0.6)\n",
    "# plt.show()\n",
    "plt.savefig('plots/FINAL/yarkoni_plot.png', dpi=120)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Supplementary Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle, os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pandas import DataFrame, concat, read_csv\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "results_file = 'arc_hierarchical_add_FINAL'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Open results file.\n",
    "print 'Loading data.'\n",
    "f = '%s.pickle' %results_file\n",
    "with open(f, 'rb') as f: results = cPickle.load(f)\n",
    "\n",
    "## Open model diagnostic file.\n",
    "info = read_csv('arc_hierarchical_add_FINAL.csv').set_index('Unnamed: 0')\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Prepare model diagnostics.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "print 'Preparing data.'\n",
    "\n",
    "## Restrict to columns of interest.\n",
    "info = info[info.columns[3:]]\n",
    "\n",
    "## Restrict to parameters of interest.\n",
    "params = np.concatenate([['beta[%s,%s]' %(n,m) for m in range(4)] +\\\n",
    "                         ['a%s[%s]' %(m,n) for m in range(2)] \n",
    "                         for n in range(28)])\n",
    "params = np.concatenate([params, ['beta_mu[%s]' %m for m in range(4)] + ['a%s_mu' %m for m in range(2)]])\n",
    "info = info.ix[params]\n",
    "\n",
    "## Append subject / parameter info.\n",
    "info['Subject'] = np.repeat(np.append(results['Subjects'], 'Group'),6)\n",
    "info['Param'] = [s[:2] if s.startswith('a') else 'b%s' %s[-2] for s in info.index]\n",
    "info = info.sort_values(['Subject','Param'])\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Re-standardize coefficients\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## See Kruschke, 2011 [pgs. 424, 566]\n",
    "print 'Standardizing coefficients.'\n",
    "X = results['X']\n",
    "\n",
    "for col in info.columns[:5]:\n",
    "    \n",
    "    ## Extract information.\n",
    "    b0 = info.loc[info.Param=='b0',col].as_matrix()\n",
    "    b3 = info.loc[info.Param=='b3',col].as_matrix()\n",
    "    a1 = info.loc[info.Param=='a1',col].as_matrix()\n",
    "    \n",
    "    ## Transform the intercept (b0).    \n",
    "    info.loc[info.Param=='b0',col] = b0 - (b3 * np.mean(X[:,-1]) / np.std(X[:,-1]))\n",
    "        \n",
    "    ## Transform the reward coefficient (b3).\n",
    "    info.loc[info.Param=='b3',col] = b3 / np.std(X[:,-1]) \n",
    "    \n",
    "    ## Transformed conflict coefficient (a1).\n",
    "    info.loc[info.Param=='a1',col] = a1 / 4.\n",
    "    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Save.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "info = info[info.columns[-2:].tolist() + info.columns[:-2].tolist()]\n",
    "info.to_csv('arc_hierarchical_add_FINAL_supp_table.csv', index=False)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Manipulation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "\n",
    "info = read_csv('stan_results/arc_hierarchical_add_FINAL_supp_table.csv')\n",
    "subjects = info.Subject.unique()[1:]\n",
    "\n",
    "for param in ['b1', 'b2', 'b3', 'a1']: \n",
    "    \n",
    "    ix = np.in1d(info.Subject, subjects)&(info.Param==param)\n",
    "    sign = np.sign(info.loc[ix, '2.5%'])\n",
    "    zero = np.sign(info.loc[ix, '2.5%']) * np.sign(info.loc[ix, '97.5%'])\n",
    "    pool = np.where(zero < 0, 0, np.where(sign > 0, 1, -1))\n",
    "    print param, np.unique(pool, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Histograms (Likelihood of Take / Reaction Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle, os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(style='white')\n",
    "sns.set_context(\"talk\")\n",
    "plt.ion()\n",
    "\n",
    "def logistic(arr): return 1. / (1 + np.exp(-arr))\n",
    "\n",
    "def hdi_mask(arr,p):\n",
    "    lb = np.percentile(arr, (100-p)/2.)\n",
    "    ub = np.percentile(arr, p+(100-p)/2.)\n",
    "    return np.where(arr < lb, np.nan, np.where(arr > ub, np.nan, arr))\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "results_file = 'arc_hierarchical_add_FINAL'\n",
    "\n",
    "## Sampling parameters.\n",
    "n_reward = 1000\n",
    "hdi = 95.\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Open results file.\n",
    "print 'Loading data.'\n",
    "f = 'stan_results/%s.pickle' %results_file\n",
    "with open(f, 'rb') as f: results = cPickle.load(f)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Re-standardize coefficients\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## See Kruschke, 2011 [pgs. 424, 566]\n",
    "\n",
    "## Make a copy.\n",
    "X = results['X']\n",
    "Beta = results['beta'].copy()\n",
    "Beta_mu = results['beta_mu'].copy()\n",
    "\n",
    "## Transform the intercept coefficient.\n",
    "Beta[:,:,0] = Beta[:,:,0] - (Beta[:,:,-1] * np.mean(X[:,-1]) / np.std(X[:,-1]))    \n",
    "Beta_mu[:,0] = Beta_mu[:,0] - (Beta_mu[:,-1] * np.mean(X[:,-1]) / np.std(X[:,-1]))    \n",
    "\n",
    "## Transform the reward coefficient.\n",
    "Beta[:,:,-1] = Beta[:,:,-1] / np.std(X[:,-1]) \n",
    "Beta_mu[:,-1] = Beta_mu[:,-1] / np.std(X[:,-1]) \n",
    "\n",
    "## Append.\n",
    "# results['Beta'] = Beta\n",
    "# results['Beta_mu'] = Beta_mu\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Compute AUC.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "print 'Computing AUC.'\n",
    "\n",
    "## Get subjects list. Preallocate space.\n",
    "n_samp, n_subj, n_pred = Beta.shape\n",
    "AUC = np.zeros((n_samp, n_subj))\n",
    "\n",
    "## Compute AUC across subjects.\n",
    "reward = np.linspace(0,1,n_reward)\n",
    "for n in range(n_subj):\n",
    "    \n",
    "    for m in range(n_pred-1):\n",
    "        \n",
    "        AUC[:,n] += logistic(Beta[:,n,:m+1].sum(axis=-1) + np.outer(Beta[:,n,-1], reward)).mean(axis=1)\n",
    "        \n",
    "AUC /= n_pred - 1.\n",
    "\n",
    "## Compute AUC for group.\n",
    "auc = np.zeros(n_samp)\n",
    "for m in range(n_pred-1):\n",
    "    auc += logistic(Beta_mu[:,:m+1].sum(axis=-1) + np.outer(Beta_mu[:,-1], reward)).mean(axis=1)\n",
    "auc /= n_pred - 1.   \n",
    "\n",
    "## Merge.\n",
    "AUC = np.concatenate([AUC,auc[:,np.newaxis]], axis=-1)\n",
    "subjects = np.append(results['Subjects'], 'Group')\n",
    "n_subj = subjects.shape[0]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting likelihood of take (AUC).\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Re-sort data by median.\n",
    "ix = np.argsort(np.median(AUC, axis=0))\n",
    "AUC = AUC[:,ix]\n",
    "subjects = subjects[ix]\n",
    "\n",
    "## Mask data outside HDI.\n",
    "mask = np.apply_along_axis(hdi_mask, 0, AUC, hdi)\n",
    "\n",
    "## Initialize plot\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "bins = np.linspace(0,1,51)\n",
    "pal = sns.cubehelix_palette(n_subj, start=0.2, rot=-0.5, dark=0.25, light=.7)\n",
    "\n",
    "for n in range(n_subj):\n",
    "    \n",
    "    ## Open ax. \n",
    "    ax = plt.subplot2grid((5,6),(n/6,n%6))\n",
    "    \n",
    "    ## Plot histogram.\n",
    "    ax.hist(mask.T[n][~np.isnan(mask.T[n])], bins, histtype='bar', facecolor=pal[n], lw=0.1)\n",
    "    ax.set_xticks(np.linspace(0,1,5))\n",
    "    ax.set_yticks([])\n",
    "    ax.tick_params(axis='x', which='major', labelsize=12)\n",
    "    if subjects[n].startswith('hc'): ax.set_title(subjects[n].upper(), fontsize=14, alpha=0.6)\n",
    "    else: ax.set_title('Group', fontsize=18, weight='bold')\n",
    "    \n",
    "    ## Turn off axes.\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('plots/FINAL/behavior_likelihood.png',dpi=120)\n",
    "plt.close()\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting RT slowdown to conflict.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Merge.\n",
    "a1 = np.concatenate([results['a1'],results['a1_mu'][:,np.newaxis]], axis=-1)\n",
    "a1 /= 4. # To get accurate RT effect.\n",
    "\n",
    "subjects = np.append(results['Subjects'], 'Group')\n",
    "n_subj = subjects.shape[0]\n",
    "\n",
    "## Re-sort data by median.\n",
    "ix = np.argsort(np.median(a1, axis=0))\n",
    "a1 = a1[:,ix]\n",
    "subjects = subjects[ix]\n",
    "\n",
    "## Mask data outside HDI.\n",
    "mask = np.apply_along_axis(hdi_mask, 0, a1, hdi)\n",
    "\n",
    "## Initialize plot\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "bins = np.linspace(0,1,51)\n",
    "pal = sns.cubehelix_palette(n_subj, start=0.2, rot=-0.5, dark=0.25, light=.7)\n",
    "\n",
    "for n in range(n_subj):\n",
    "    \n",
    "    ## Open ax. \n",
    "    ax = plt.subplot2grid((5,6),(n/6,n%6))\n",
    "    \n",
    "    ## Plot histogram.\n",
    "    ax.hist(mask.T[n][~np.isnan(mask.T[n])], bins, color=pal[n], lw=0.1)\n",
    "    ax.set_xticks(np.linspace(0,1,5))\n",
    "    ax.set_yticks([])\n",
    "    ax.tick_params(axis='x', which='major', labelsize=12)\n",
    "    if subjects[n].startswith('hc'): ax.set_title(subjects[n].upper(), fontsize=14, alpha=0.6)\n",
    "    else: ax.set_title('Group', fontsize=18, weight='bold')\n",
    "    \n",
    "    ## Turn off axes.\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('plots/FINAL/behavior_rt_conflict.png',dpi=120)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Violin Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data.\n",
      "Computing AUC.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import cPickle, os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "sns.set_style(style='white')\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "plt.ion()\n",
    "\n",
    "def logistic(arr): return 1. / (1 + np.exp(-arr))\n",
    "\n",
    "def HDIofMCMC(arr, credMass=0.95):\n",
    "    '''\n",
    "    Computes highest density interval from a sample of representative values,\n",
    "    estimated as shortest credible interval. Functions for computing HDI's are \n",
    "    explained in Chapter 25 of Doing Bayesian Data Analysis, Second Edition.\n",
    "    \n",
    "    INPUTS:\n",
    "    -- arr: a vector of representative values from a probability distribution.\n",
    "    -- credMass: a scalar between 0 and 1, indicating the mass within the credible\n",
    "       interval that is to be estimated.\n",
    "    '''\n",
    "    sortedPts = np.sort(arr)\n",
    "    ciIdxInc = np.ceil(credMass * len( sortedPts )).astype(int)\n",
    "    nCIs = len( sortedPts ) - ciIdxInc\n",
    "    ciWidth = [ sortedPts[ i + ciIdxInc ] - sortedPts[ i ] for i in np.arange(nCIs).astype(int) ]\n",
    "    HDImin = sortedPts[ np.argmin( ciWidth ) ]\n",
    "    HDImax = sortedPts[ np.argmin( ciWidth ) + ciIdxInc ]\n",
    "    return HDImin, HDImax\n",
    "\n",
    "def hdi_mask(arr,p):\n",
    "    lb, ub = HDIofMCMC(arr, p)\n",
    "    return np.where(arr < lb, np.nan, np.where(arr > ub, np.nan, arr))\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "results_file = 'arc_hierarchical_add_FINAL'\n",
    "\n",
    "## Sampling parameters.\n",
    "n_reward = 1000\n",
    "hdi = 0.95\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Open results file.\n",
    "print 'Loading data.'\n",
    "f = 'stan_results/%s.pickle' %results_file\n",
    "with open(f, 'rb') as f: results = cPickle.load(f)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Re-standardize coefficients\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## See Kruschke, 2011 [pgs. 424, 566]\n",
    "\n",
    "## Make a copy.\n",
    "X = results['X']\n",
    "Beta = results['beta'].copy()\n",
    "Beta_mu = results['beta_mu'].copy()\n",
    "\n",
    "## Transform the intercept coefficient.\n",
    "Beta[:,:,0] = Beta[:,:,0] - (Beta[:,:,-1] * np.mean(X[:,-1]) / np.std(X[:,-1]))    \n",
    "Beta_mu[:,0] = Beta_mu[:,0] - (Beta_mu[:,-1] * np.mean(X[:,-1]) / np.std(X[:,-1]))    \n",
    "\n",
    "## Transform the reward coefficient.\n",
    "Beta[:,:,-1] = Beta[:,:,-1] / np.std(X[:,-1]) \n",
    "Beta_mu[:,-1] = Beta_mu[:,-1] / np.std(X[:,-1]) \n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Compute AUC.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "print 'Computing AUC.'\n",
    "\n",
    "## Get subjects list. Preallocate space.\n",
    "n_samp, n_subj, n_pred = Beta.shape\n",
    "AUC = np.zeros((n_samp, n_subj))\n",
    "\n",
    "## Compute AUC across subjects.\n",
    "reward = np.linspace(0,1,n_reward)\n",
    "for n in range(n_subj):\n",
    "    \n",
    "    for m in range(n_pred-1):\n",
    "        \n",
    "        AUC[:,n] += logistic(Beta[:,n,:m+1].sum(axis=-1) + np.outer(Beta[:,n,-1], reward)).mean(axis=1)\n",
    "        \n",
    "AUC /= n_pred - 1.\n",
    "\n",
    "## Compute AUC for group.\n",
    "auc = np.zeros(n_samp)\n",
    "for m in range(n_pred-1):\n",
    "    auc += logistic(Beta_mu[:,:m+1].sum(axis=-1) + np.outer(Beta_mu[:,-1], reward)).mean(axis=1)\n",
    "auc /= n_pred - 1.   \n",
    "\n",
    "## Delete variables (unnecessary).\n",
    "del Beta, Beta_mu\n",
    "\n",
    "## Mask data outside HDI.\n",
    "AUC = np.apply_along_axis(hdi_mask, 0, AUC, hdi)\n",
    "auc = hdi_mask(auc, hdi)\n",
    "\n",
    "## Merge data.\n",
    "AUC = np.concatenate([AUC,auc[:,np.newaxis]],axis=-1)\n",
    "subjects = np.append(results['Subjects'], 'Group')\n",
    "\n",
    "## Re-sort by median AUC.\n",
    "ix = np.argsort(np.nanmedian(AUC,0))\n",
    "AUC = AUC[:,ix]\n",
    "subjects = subjects[ix]\n",
    "\n",
    "## Prepare subjects data.\n",
    "AUC = AUC.T.flatten()\n",
    "subjects = np.concatenate([np.repeat(subject,n_reward) for subject in subjects])\n",
    "\n",
    "## Place into DataFrame.\n",
    "df = DataFrame(np.vstack([AUC,subjects]).T, columns=('AUC','Subjects'))\n",
    "df['AUC'] = df['AUC'].astype(float)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting likelihood of take (AUC).\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Generate colors.\n",
    "colors = ['#7ec0ee' if s.startswith('hc') else '#74c476' for s in df.Subjects.unique()]\n",
    "palette = sns.color_palette(colors)\n",
    "\n",
    "## Generate violinplot.\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
    "sns.violinplot(x='Subjects', y='AUC',data=df, cut=0, scale='count', width=0.7,\n",
    "               linewidth=0.1, palette=palette, saturation=1, scale_hue=False, ax=ax)\n",
    "\n",
    "## Add horizontal lines.\n",
    "xmin, xmax = ax.get_xlim()\n",
    "sns.plt.hlines(df.loc[df.Subjects=='Group','AUC'].median(), xmin, xmax,\n",
    "          linestyle='--', linewidth=0.75, alpha=0.5, zorder=-1)\n",
    "\n",
    "## Add legend.\n",
    "ax.plot([],[],color='#74c476',label='Group')\n",
    "ax.plot([],[],color='#7ec0ee',label='Subject')\n",
    "legend = ax.legend(loc=4, frameon=False, borderaxespad=0, handletextpad=0.5,\n",
    "                  borderpad=0.5, handlelength=1.75)\n",
    "for l in legend.get_lines(): \n",
    "    l.set_linewidth(10)\n",
    "    l.set_solid_capstyle('butt')\n",
    "\n",
    "## Fix axes.\n",
    "# ax.set_xticklabels(['s%s' %s[-2:] if s.startswith('hc') else 'G' for s in df.Subject.unique()])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel(r'Average Likelihood-of-Take ($\\theta$)')\n",
    "\n",
    "## Save.\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('plots/FINAL/behavior_likelihood_violin.png',dpi=120)\n",
    "plt.close()\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Prepare RT-Conflict Slope Data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Extract and merge.\n",
    "a1 = np.concatenate([results['a1'],results['a1_mu'][:,np.newaxis]], axis=-1)\n",
    "a1 /= 4. # To get accurate RT effect.\n",
    "\n",
    "subjects = np.append(results['Subjects'], 'Group')\n",
    "n_subj = subjects.shape[0]\n",
    "\n",
    "## Re-sort data by median.\n",
    "ix = np.argsort(np.median(a1, axis=0))\n",
    "a1 = a1[:,ix]\n",
    "subjects = subjects[ix]\n",
    "\n",
    "## Mask data outside HDI.\n",
    "a1 = np.apply_along_axis(hdi_mask, 0, a1, hdi)\n",
    "\n",
    "## Prepare subjects data.\n",
    "a1 = a1.T.flatten()\n",
    "subjects = np.concatenate([np.repeat(subject,n_reward) for subject in subjects])\n",
    "\n",
    "## Place into DataFrame.\n",
    "df = DataFrame(np.vstack([a1,subjects]).T, columns=('a1','Subjects'))\n",
    "df['a1'] = df['a1'].astype(float)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting likelihood of take (AUC).\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Generate colors.\n",
    "colors = ['#7ec0ee' if s.startswith('hc') else '#74c476' for s in df.Subjects.unique()]\n",
    "palette = sns.color_palette(colors)\n",
    "\n",
    "## Generate violinplot.\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
    "sns.violinplot(x='Subjects', y='a1',data=df, cut=0, scale='count', width=0.7,\n",
    "               linewidth=0.1, palette=palette, saturation=1, scale_hue=False, ax=ax)\n",
    "\n",
    "## Add horizontal lines.\n",
    "xmin, xmax = ax.get_xlim()\n",
    "sns.plt.hlines(df.loc[df.Subjects=='Group','a1'].median(), xmin, xmax,\n",
    "          linestyle='--', linewidth=0.75, alpha=0.5, zorder=-1)\n",
    "\n",
    "## Add legend.\n",
    "ax.plot([],[],color='#74c476',label='Group')\n",
    "ax.plot([],[],color='#7ec0ee',label='Subject')\n",
    "legend = ax.legend(loc=4, frameon=False, borderaxespad=0, handletextpad=0.5,\n",
    "                  borderpad=0.5, handlelength=1.75)\n",
    "for l in legend.get_lines(): \n",
    "    l.set_linewidth(10)\n",
    "    l.set_solid_capstyle('butt')\n",
    "\n",
    "## Fix axes.\n",
    "# ax.set_xticklabels(['s%s' %s[-2:] if s.startswith('hc') else 'G' for s in df.Subject.unique()])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel(r'Conflict-RT Slope ($\\alpha_1$)')\n",
    "\n",
    "## Save.\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('plots/FINAL/behavior_rt_conflict_violin.png',dpi=120)\n",
    "plt.close()\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mindboggle Parcellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mne import read_label\n",
    "from surfer import Brain\n",
    "from seaborn import color_palette\n",
    "%matplotlib qt4\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "fs_dir = '/space/lilli/1/users/DARPA-Recons'\n",
    "subject = 'fsaverage'\n",
    "surface = 'inflated'\n",
    "hemi = 'lh'\n",
    "\n",
    "## Label paramaters.\n",
    "label_dir = '/space/lilli/1/users/DARPA-Recons/fscopy/label/dkt40'\n",
    "roi_list = ['caudalanteriorcingulate', 'rostralanteriorcingulate', 'posteriorcingulate',\n",
    "            'superiorfrontal', 'medialorbitofrontal', 'rostralmiddlefrontal', 'caudalmiddlefrontal',\n",
    "            'parsopercularis', 'parstriangularis', 'parsorbitalis', 'lateralorbitofrontal', 'insula']\n",
    "\n",
    "colors = [[0.78329874347238, 0.687243385525311, 0.8336793640080622],\n",
    "          [0.1257208769520124, 0.47323337360924367, 0.707327968232772],\n",
    "            [0.999907727802501, 0.5009919264737298, 0.005121107311809869],\n",
    "          [0.21171857311445125, 0.6332641510402455, 0.1812226118410335],\n",
    "          [0.6941176652908325, 0.3490196168422699, 0.1568627506494522],\n",
    "          [0.42485198495434734, 0.2511495584950722, 0.6038600774372326],\n",
    "          [0.983206460055183, 0.5980161709820524, 0.5942330108845937],\n",
    "          [0.9917570170234231, 0.7464821371669862, 0.4340176893507733],\n",
    "          [0.8905959311653586, 0.10449827132271793, 0.111080354627441],\n",
    "          [0.9976009228650261, 0.9948942715046452, 0.5965244373854468],\n",
    "          [0.6889965575115352, 0.8681737867056154, 0.5437601194662207],\n",
    "          [0.6509804129600525, 0.8078431487083435, 0.8901960849761963]]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Visualize brain.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load labels.\n",
    "roi_list = [read_label('%s/%s-%s.label' %(label_dir,roi,hemi), subject=subject) for roi in roi_list]\n",
    "\n",
    "## Make brain.\n",
    "brain = Brain(subject, hemi, surface, background='white', subjects_dir=fs_dir)\n",
    "for roi, color in zip(roi_list, colors): brain.add_label(roi, color=color)\n",
    "for view in ['medial','lateral']:\n",
    "    brain.show_view(view)\n",
    "    brain.save_image('plots/FINAL/mindboggle_%s.png' %view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-panel Deliberation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from surfer import Brain\n",
    "%matplotlib qt4\n",
    "\n",
    "fs_dir = '/space/lilli/1/users/DARPA-Recons'\n",
    "img_dir = 'plots/FINAL'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "\n",
    "## I/O parameters.\n",
    "sm = 6\n",
    "fd = 0.9\n",
    "contrast = 'Delib'\n",
    "overlay = 'psc'\n",
    "\n",
    "## Pysurfer parameters.\n",
    "surface = 'inflated'\n",
    "views = ['lateral','medial']\n",
    "size = (1200,800)\n",
    "bg_color = 'black'\n",
    "\n",
    "fmin = 0.04 # min value\n",
    "fmax = 0.20 # max value\n",
    "\n",
    "## Label parameters.\n",
    "label_dir = 'fmri_second_levels/labels/seeds_%s' %contrast\n",
    "labels = ['dacc', 'dlpfc', 'insula', 'mcc', 'pre_sma']\n",
    "label_color = 'k'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plot.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Initialize brain.\n",
    "brains = Brain(\"fsaverage\", 'split', surface, views=views, size=size,\n",
    "              background=bg_color, subjects_dir=fs_dir)\n",
    "\n",
    "## Add overlay.\n",
    "for hemi in ['lh','rh']:\n",
    "    f = os.path.join('fmri_second_levels', 'FINAL.%s.%s.%s.%s' %(sm, fd, hemi, contrast), '%s.nii.gz' %overlay)\n",
    "    brains.add_overlay(f, min=fmin, max=fmax, sign=\"pos\", hemi=hemi)\n",
    "    \n",
    "## Add labels.\n",
    "# for label in labels:\n",
    "#     for hemi in ['lh','rh']:\n",
    "#         f = os.path.join(label_dir, 'fig_%s-%s.label' %(label,hemi))\n",
    "#         brains.add_label(f, color=label_color, borders=True, hemi=hemi)\n",
    "    \n",
    "## Update views.\n",
    "brains.set_distance(300)\n",
    "brains.hide_colorbar(0,0)\n",
    "brains.hide_colorbar()\n",
    "\n",
    "brains.save_image('plots/FINAL/delib.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-panel Delibmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "from surfer import Brain\n",
    "%matplotlib qt4\n",
    "\n",
    "fs_dir = '/space/lilli/1/users/DARPA-Recons'\n",
    "img_dir = 'plots/FINAL'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "sm = 6\n",
    "fd = 0.9\n",
    "contrast = 'DelibMod'\n",
    "overlay = 'psc'\n",
    "\n",
    "## Pysurfer parameters.\n",
    "surface = 'pial'\n",
    "size = (800,400)\n",
    "bg_color = 'black'\n",
    "\n",
    "fmin = 1e-6 # min value\n",
    "fmax = 0.05 # max value\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plot.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "hemis = ['lh','rh','rh']\n",
    "views = ['lateral','lateral','medial']\n",
    "params = [dict(azimuth=150, roll=90),dict(azimuth=30, roll=270),dict(azimuth=180, roll=90)]\n",
    "distances = [280,280,280]\n",
    "\n",
    "for hemi, view, param, dist in zip(hemis,views,params,distances):\n",
    "\n",
    "    ## Initialize brain.\n",
    "    brain = Brain(\"fsaverage\", hemi, surface, views=[view], size=size,\n",
    "                  background=bg_color, subjects_dir=fs_dir)\n",
    "\n",
    "    ## Add overlay.\n",
    "    f = os.path.join('fmri_second_levels', 'FINAL.%s.%s.%s.%s' %(sm, fd, hemi, contrast), '%s.nii.gz' %overlay)\n",
    "    brain.add_overlay(f, min=fmin, max=fmax, sign=\"pos\", hemi=hemi)\n",
    "    \n",
    "    ## Update views.\n",
    "    brain.show_view(param)\n",
    "    brain.set_distance(dist)\n",
    "    brain.hide_colorbar()\n",
    "    time.sleep(5)\n",
    "    brain.save_image('plots/FINAL/delibmod_%s_%s.png' %(hemi,view))\n",
    "    \n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pysurfer Colorbar\n",
    "Convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from surfer import Brain\n",
    "%matplotlib qt4\n",
    "\n",
    "fs_dir = '/space/lilli/1/users/DARPA-Recons'\n",
    "img_dir = 'plots/FINAL'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Pysurfer parameters.\n",
    "size = (1200,800)\n",
    "bg_color = 'black'\n",
    "\n",
    "fmin = 0.00 # min value\n",
    "fmax = 0.05 # max value\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plot.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Initialize brain.\n",
    "brains = Brain(\"fsaverage\", 'lh', 'inflated', size=size,\n",
    "              background=bg_color, subjects_dir=fs_dir)\n",
    "\n",
    "## Add overlay.    \n",
    "f = 'fmri_second_levels/FINAL.6.0.9.lh.Delib/psc.nii.gz'\n",
    "brains.add_overlay(f, min=fmin, max=fmax, sign=\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brains.data_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "827px",
   "left": "0px",
   "right": "auto",
   "top": "106px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
